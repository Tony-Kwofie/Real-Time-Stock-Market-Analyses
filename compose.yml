

# -------------------- SERVICES --------------------
services:

  spark-master:
    image: spark:3.5.1-python3
    container_name: spark-master
    command:
      - "/opt/spark/bin/spark-class"
      - "org.apache.spark.deploy.master.Master"
      - "--host"
      - "spark-master"
      - "--port"
      - "7077"
      - "--webui-port"
      - "8080"
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
    ports:
      - "8081:8080"
      - "7077:7077"
    volumes:
      - spark-data:/opt/spark-data
    networks:
      - stock_data

  spark-worker:
    image: spark:3.5.1-python3
    container_name: spark-worker
    command:
      - "/opt/spark/bin/spark-class"
      - "org.apache.spark.deploy.worker.Worker"
      - "spark://spark-master:7077"
      - "--webui-port"
      - "8081"
    environment:
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2G
    depends_on:
      - spark-master
    volumes:
      - spark-data:/opt/spark-data
    networks:
      - stock_data

  consumer:
    build:
      context: ./consumer
      dockerfile: dockerfile   # Change to Dockerfile if you rename it
    image: stream_consumer
    container_name: consumer
    depends_on:
      - spark-master
      - kafka
    restart: unless-stopped
    volumes:
      - ivy_cache:/opt/spark/work-dir/.ivy2
    networks:
      - stock_data

  kafka:
    image: confluentinc/cp-kafka:7.4.10
    container_name: kafka
    hostname: kafka
    ports:
      - "9092:9092"
      - "9094:9094"
    environment:
      KAFKA_KRAFT_MODE: "true"
      KAFKA_PROCESS_ROLES: controller,broker
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"

      KAFKA_LISTENERS: PLAINTEXT_INTERNAL://0.0.0.0:9092,PLAINTEXT_EXTERNAL://0.0.0.0:9094,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT_INTERNAL://kafka:9092,PLAINTEXT_EXTERNAL://localhost:9094

      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT_INTERNAL:PLAINTEXT,PLAINTEXT_EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      CLUSTER_ID: "jbzXiYiPQ8a2ejaWHK4Q3w"

    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - stock_data

  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:v0.7.2
    ports:
      - "8085:8080"
    depends_on:
      - kafka
    environment:
      KAFKA_CLUSTERS_0_NAME: stock_data
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      DYNAMIC_CONFIG_ENABLED: "true"
    networks:
      - stock_data

  postgres:
    image: debezium/postgres:17
    container_name: postgres_db
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: stock_data
    ports:
      - "5434:5432"
    volumes:
      - postgres_data:/var/lib/postgres/data
    networks:
      - stock_data

  pgadmin:
    image: dpage/pgadmin4:9
    container_name: pgadmin
    restart: always
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@admin.com
      PGADMIN_DEFAULT_PASSWORD: admin
    ports:
      - "5050:80"
    depends_on:
      - postgres
    networks:
      - stock_data


# -------------------- VOLUMES --------------------
volumes:
  spark-data:
  kafka_data:
  ivy_cache:
  postgres_data:


# -------------------- NETWORKS --------------------
networks:
  stock_data: